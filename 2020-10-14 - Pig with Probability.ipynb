{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version:  0.2.23\n"
     ]
    }
   ],
   "source": [
    "from Game import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rules of the Game"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- before each roll, we can either choose to roll or hold\n",
    "- roll a die\n",
    "    - if it is a 1, turn score goes to zero (or 1), the turn stops and goes to the next player\n",
    "    - if not a 1, add to the turn score the number rolled, and have another turn\n",
    "- hold\n",
    "    - turn score gets added to my current score\n",
    "    - goes to the next player\n",
    "- first to 21 wins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. what is a move?  (how do we represent it, what are possibilities)\n",
    "    - \"roll\", \"hold\"\n",
    "2. what is a state?  (how do we represent it, what are possibilities)\n",
    "    - your current score, their current score, turn score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_moves(state,player):\n",
    "    return [\"roll\",\"hold\"]\n",
    "\n",
    "def initial_state():\n",
    "    # your current score, their current score, turn score\n",
    "    return [0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_state(state):\n",
    "    print(\"Player 1 score is \",state[0])\n",
    "    print(\"Player 2 score is \",state[1])\n",
    "    print(\"Turn score is \",state[2])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def win_status(state,player):\n",
    "    \n",
    "    # playing until 101\n",
    "    max_score=101\n",
    "    \n",
    "    if player==1:\n",
    "        current_score=state[0]\n",
    "        other_score=state[1]\n",
    "    else:\n",
    "        current_score=state[1]\n",
    "        other_score=state[0]\n",
    "        \n",
    "    turn_score=state[2]\n",
    "    \n",
    "    if current_score+turn_score>=max_score:\n",
    "        return 'win'\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_state(state,player,move):\n",
    "    \n",
    "    # if hold, update the scores\n",
    "    \n",
    "    # if roll, then random number 1-6, if 1, ....\n",
    "    # update turn score\n",
    "    new_state=state\n",
    "    \n",
    "    if move=='hold':\n",
    "        \n",
    "        # state[player-1]+=state[2]\n",
    "        \n",
    "        if player==1:\n",
    "            new_state[0]+=state[2]  # add the turn score to player 1's current score\n",
    "        else:\n",
    "            new_state[1]+=state[2]  # add the turn score to player 1's current score\n",
    "        \n",
    "        new_state[2]=0  # reset the turn score\n",
    "        \n",
    "    else:  #  roll\n",
    "        dice=random.randint(1,6)\n",
    "        \n",
    "        if dice==1:\n",
    "            new_state[2]=0  # reset the turn score\n",
    "        else:\n",
    "            new_state[2]+=dice\n",
    "            \n",
    "    \n",
    "    return new_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def repeat_move(state,player,move):\n",
    "    turn_score=state[2]\n",
    "    \n",
    "    if turn_score>0:\n",
    "        return True\n",
    "    \n",
    "    return False\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def human_move(state,player):\n",
    "    print(\"Player \",player)\n",
    "    s=input(\"hold or roll?\")\n",
    "    \n",
    "    if s[0]=='h':\n",
    "        return 'hold'\n",
    "    else:\n",
    "        return 'roll'\n",
    "    \n",
    "human_agent=Agent(human_move)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_move(state,player):\n",
    "    possible_moves=valid_moves(state,player)\n",
    "    move=random.choice(possible_moves)\n",
    "    return move\n",
    "\n",
    "\n",
    "random_agent=Agent(random_move)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_score=101\n",
    "saved_p={}\n",
    "saved_whether_roll={}\n",
    "\n",
    "def p_win(i,j,k):  # i = my score, j is the other score, k is the turn score\n",
    "    \n",
    "    if i+k>=max_score:\n",
    "        return 1\n",
    "    \n",
    "    if j>=max_score:\n",
    "        return 0.0\n",
    "    \n",
    "    \n",
    "    if (i,j,k) in saved_p:\n",
    "        return saved_p[(i,j,k)]\n",
    "    \n",
    "\n",
    "    # if I roll a one\n",
    "    #p_win_roll=1-(probability that I lose, handing it off to the other)\n",
    "    p_win_roll=1-p_win(j,i+1,0)\n",
    "    \n",
    "    # if I roll a two, three,\n",
    "    for dice in [2,3,4,5,6]:  # range(2,6+1) is equal but unreadable\n",
    "        p_win_roll+=p_win(i,j,k+dice)\n",
    "    \n",
    "    p_win_roll/=6\n",
    "    \n",
    "    if k==0:  # add 1 even when the turn score is zero\n",
    "        p_win_hold=1-p_win(j,i+1,0)\n",
    "    else:\n",
    "        p_win_hold=1-p_win(j,i+k,0)\n",
    "\n",
    "        \n",
    "    # assume that we are rational\n",
    "    if p_win_roll>p_win_hold:\n",
    "        p=p_win_roll\n",
    "        saved_whether_roll[(i,j,k)]=True\n",
    "    else:\n",
    "        p=p_win_hold\n",
    "        saved_whether_roll[(i,j,k)]=False\n",
    "        \n",
    "    \n",
    "    saved_p[(i,j,k)]=p\n",
    "    \n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probability_move(state,player):\n",
    "    \n",
    "    i,j,k=state\n",
    "    \n",
    "    p=p_win(i,j,k)\n",
    "    roll=saved_whether_roll[(i,j,k)]\n",
    "    \n",
    "    if roll:\n",
    "        return \"roll\"\n",
    "    else:\n",
    "        return \"hold\"\n",
    "    \n",
    "probability_agent=Agent(probability_move)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Game.minimax import *\n",
    "def minimax_move(state,player):\n",
    "\n",
    "    values,moves=minimax_values(state,player,display=False)\n",
    "    return top_choice(moves,values)\n",
    "\n",
    "\n",
    "minimax_agent=Agent(minimax_move)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def skittles_move(state,player,info):\n",
    "    S=info.S\n",
    "    last_action=info.last_action\n",
    "    last_state=info.last_state\n",
    "    \n",
    "    \n",
    "    # if Ive never seen this state before\n",
    "    if not state in S:\n",
    "        actions=valid_moves(state,player)\n",
    "\n",
    "        S[state]=Table()\n",
    "        for action in actions:\n",
    "            S[state][action]=3     \n",
    "    \n",
    "    move=weighted_choice(S[state])  # weighted across actions\n",
    "    \n",
    "    # what if there are no skittles for a particular state?\n",
    "    # move is None in that case\n",
    "    \n",
    "    if move is None:\n",
    "        # learn a little bit\n",
    "        if last_state:\n",
    "            S[last_state][last_action]=S[last_state][last_action]-1\n",
    "            if S[last_state][last_action]<0:\n",
    "                S[last_state][last_action]=0\n",
    "        \n",
    "        move=random_move(state,player)\n",
    "    \n",
    "    return move\n",
    "\n",
    "def skittles_after(status,player,info):\n",
    "    S=info.S\n",
    "    last_action=info.last_action\n",
    "    last_state=info.last_state\n",
    "\n",
    "    if status=='lose':\n",
    "        # learn a little bit\n",
    "        S[last_state][last_action]=S[last_state][last_action]-1\n",
    "        if S[last_state][last_action]<0:\n",
    "            S[last_state][last_action]=0\n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "skittles_agent=Agent(skittles_move)\n",
    "skittles_agent.S=Table()\n",
    "skittles_agent.post=skittles_after\n",
    "\n",
    "\n",
    "skittles_agent2=Agent(skittles_move)\n",
    "skittles_agent2.S=Table()\n",
    "skittles_agent2.post=skittles_after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Q_move(state,player,info):\n",
    "    Q=info.Q\n",
    "    last_action=info.last_action\n",
    "    last_state=info.last_state\n",
    "    \n",
    "    α=info.α\n",
    "    γ=info.γ\n",
    "    ϵ=info.ϵ\n",
    "    \n",
    "\n",
    "    # if Ive never seen this state before\n",
    "    if not state in Q:\n",
    "        actions=valid_moves(state,player)\n",
    "\n",
    "        Q[state]=Table()\n",
    "        for action in actions:\n",
    "            Q[state][action]=0     \n",
    "    \n",
    "    # deal with random vs top choice here\n",
    "    if random.random()<ϵ:\n",
    "        move=random_move(state,player)  \n",
    "    else:\n",
    "        move=top_choice(Q[state]) \n",
    "    \n",
    "    # what if there are no skittles for a particular state?\n",
    "    # move is None in that case\n",
    "    \n",
    "    if not last_action is None:  # not the first move\n",
    "        # learn a little bit\n",
    "        # change equation here\n",
    "        reward=0\n",
    "        \n",
    "        # Bellman equation\n",
    "        Q[last_state][last_action] += α*(reward+\n",
    "                         γ*max([Q[state][a] for a in Q[state]])  - \n",
    "                                Q[last_state][last_action])\n",
    "    \n",
    "        \n",
    "    \n",
    "    return move\n",
    "\n",
    "def Q_after(status,player,info):\n",
    "    Q=info.Q\n",
    "    last_action=info.last_action\n",
    "    last_state=info.last_state\n",
    "\n",
    "    α=info.α\n",
    "    γ=info.γ\n",
    "    ϵ=info.ϵ\n",
    "    \n",
    "    if status=='lose':\n",
    "        reward=-1\n",
    "    elif status=='win':\n",
    "        reward=1\n",
    "    elif status=='stalemate':\n",
    "        reward=0.5\n",
    "    else:\n",
    "        reward=0\n",
    "        \n",
    "    # learn a little bit\n",
    "    Q[last_state][last_action] += α*(reward-Q[last_state][last_action])\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1_agent=Agent(Q_move)\n",
    "Q1_agent.Q=LoadTable('Q1_Pig_data.json')\n",
    "Q1_agent.post=Q_after\n",
    "\n",
    "Q1_agent.α=0.3  # learning rate\n",
    "Q1_agent.γ=0.9  # memory constant, discount factor\n",
    "Q1_agent.ϵ=0.1  # probability of a random move during learning\n",
    "\n",
    "Q2_agent=Agent(Q_move)\n",
    "Q2_agent.Q=LoadTable('Q2_Pig_data.json')\n",
    "Q2_agent.post=Q_after\n",
    "\n",
    "Q2_agent.α=0.3  # learning rate\n",
    "Q2_agent.γ=0.9  # memory constant, discount factor\n",
    "Q2_agent.ϵ=0.1  # probability of a random move during learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "g=Game(number_of_games=1000)\n",
    "g.display=False\n",
    "g.run(probability_agent,random_agent);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99.6, 0.4, 0.0)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.percent_win_lose_tie()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bob_move(state,player):\n",
    "    return \"roll\"\n",
    "\n",
    "bob=Agent(bob_move)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "g=Game(number_of_games=1000)\n",
    "g.display=False\n",
    "g.run(probability_agent,bob);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(88.3, 11.7, 0.0)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.percent_win_lose_tie()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
